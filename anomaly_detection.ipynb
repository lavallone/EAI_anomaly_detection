{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# [PG01] Unsupervised anomaly detection in industrial image data with autoencoders"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> In this notebook we are going to develop the final projet for the *EAI course* held by Christian Napoli. The *dataset* is the well know **MVtec AD** described in the paper that has been referenced on our report. For this reason we won't spend much time in replicating the *analysis* and *statistics* that can be found on the original article."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Imports & Download"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# install the requirements\n","%pip install -r requirements.txt > /dev/null\n","# set to false if you already have the dataset\n","download_dataset = False \n","if download_dataset:\n","    %cd dataset\n","    !bash dataset/download_dataset.sh\n","    %cd .."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import dataclasses\n","from src.data_module import MVTec_Dataset, MVTec_DataModule\n","from src.AE_simple import AE\n","from src.AE_CODE import CODE_AE\n","from src.AE_mixer import Mixer_AE\n","from src.hyperparameters import Hparams\n","from src.train import train_model\n","from dataclasses import asdict\n","import matplotlib.pyplot as plt\n","import wandb\n","import pprint\n","import torchvision\n","import pytorch_lightning as pl\n","import gc\n","from collections import Counter\n","import seaborn as sns\n","from tqdm import tqdm\n","# reproducibility stuff\n","import numpy as np\n","import random\n","import torch\n","np.random.seed(0)\n","random.seed(0)\n","torch.cuda.manual_seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n","torch.backends.cudnn.benchmark = False\n","_ = pl.seed_everything(0)\n","# to have a better workflow using notebook https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n","# these commands allow to update the .py codes imported instead of re-importing everything every time.\n","%load_ext autoreload\n","%autoreload 2\n","%env WANDB_NOTEBOOK_NAME = ./anomaly_detection.ipynb\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# login wandb to have the online logger. It is really useful since it stores all the plots and evolution of the model\n","# check also https://docs.wandb.ai/guides/integrations/lightning\n","wandb.login()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Utilities"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# to make sure everything works we just plot a sample of our images\n","def plot_objects(images, \n","                images_per_row, \n","                border = 10, \n","                pad_value = 1,\n","                title = 'Industrial images',\n","                figsize = (16,16)):\n","    plt.figure(figsize = figsize)\n","    plt.imshow(torchvision.utils.make_grid(images,images_per_row,border,pad_value=pad_value).permute(1, 2, 0))\n","    plt.title(title)\n","    plt.axis('off')\n","\n","# these are the performance we metric we compute to compare them with the 2019 MVTec paper results.\n","# Two metrics are needed:\n","# - accuracy of objects predicted as anomaly. --> it's exactly the recall\n","# - accuracy of objects predicted as normal. --> it's a different metrics --> T_normal / T_normal+F_anomaly\n","# POSITIVES are anomalies and NEGATIVES are the normal instances\n","def performance_evaluation(model, dataset):\n","    c2id = dataset.c2id # class to id\n","    id2c = dataset.id2c # id to class\n","    # we  utilize Counter() because we compute the metrics for each category class!\n","    total_anom = Counter() # TP+FN\n","    total_norm = Counter() # TN+FP\n","    total_predicted_anom = Counter() # TP+FP\n","    true_anom = Counter() # TP\n","    true_norm = Counter() # TN\n","    model.eval()\n","    device = model.device\n","    with torch.no_grad():\n","        for batch in tqdm(dataset.val_dataloader()):\n","            pred = model.anomaly_prediction(batch[\"img\"].to(device), batch=batch)\n","            true_anomaly_mask = batch[\"label\"]>0 # True if is an anomaly --> returns a list [T,F,F,T,F,...]\n","            true_normal_mask = batch[\"label\"]==0 # True if is an anomaly-free instance\n","            pred_fila = pred>0\n","            total_anom.update([id2c[i] for i in batch[\"class_obj\"][true_anomaly_mask].tolist()]) # {\"tile\":2, \"carpet\":3, ...}\n","            total_norm.update([id2c[i] for i in batch[\"class_obj\"][true_normal_mask].tolist()])\n","            total_predicted_anom.update([id2c[i] for i in batch[\"class_obj\"][pred_fila].tolist()])\n","            \n","            pred_good_mask = batch[\"label\"]==pred\n","            pred_anomaly = pred==1\n","            pred_normal = pred==0\n","            true_anom.update([id2c[i] for i in batch[\"class_obj\"][torch.logical_and(pred_good_mask, pred_anomaly)].tolist()])\n","            true_norm.update([id2c[i] for i in batch[\"class_obj\"][torch.logical_and(pred_good_mask, pred_normal)].tolist()])\n","\n","        tot_conf_matrix = np.array([[0,0],[0,0]])\n","        all_inner_acc_norm = list()\n","        all_inner_acc_anom = list()\n","        all_recall = list()\n","        all_precision = list()\n","        all_f1_score = list()\n","        for k in total_anom.keys(): # for each class k\n","            all_a_k = total_anom[k]\n","            all_n_k = total_norm[k]\n","            all_pred_a_k = total_predicted_anom[k]\n","            class_total = all_a_k + all_n_k\n","            true_a_k = true_anom[k]\n","            true_n_k = true_norm[k]\n","            \n","            precision = 0 if (all_pred_a_k==0 or true_a_k==0) else float(true_a_k) / all_pred_a_k # equals to zero also in the undefined case\n","            all_precision.append(precision)\n","            recall = 0 if (all_a_k==0 or true_a_k==0) else float(true_a_k) / all_a_k\n","            all_recall.append(recall)\n","            f1_score = 0 if (precision==0 and recall==0) else 2*precision*recall/(precision+recall)\n","            all_f1_score.append(f1_score)\n","            \n","            acc_norm = 0 if (all_n_k==0 or true_n_k==0) else float(true_n_k) / all_n_k\n","            all_inner_acc_norm.append(acc_norm)\n","            acc_anom = recall # float(true_a_k) / all_a_k\n","            all_inner_acc_anom.append(acc_anom)\n","            print(\"[\"+k.upper()+\"]\")\n","            print(f\"Total number: {class_total}\")\n","            print(f\"anomaly-free predicted correctly: {acc_norm:.3f}\")\n","            print(f\"anomalies predicted correctly: {acc_anom:.3f}\")\n","            print(f\"precision: {precision:.3f}\")\n","            print(f\"recall: {recall:.3f}\")\n","            print(f\"f1_score: {f1_score:.3f}\")\n","            print(\"-------------------------------------------------\")\n","            tp = true_a_k\n","            fp = all_n_k-true_n_k\n","            fn = all_a_k-true_a_k\n","            tn = true_n_k\n","            confusion_matrix = np.array([[tn, fn],[fp,tp]])\n","            tot_conf_matrix += confusion_matrix\n","        \n","        print()\n","        print(f\"AVERAGE RECALL for all the classes: {np.array(all_recall).mean()}\")\n","        print()\n","        print(f\"AVERAGE PRECISION for all the classes: {np.array(all_precision).mean()}\")\n","        print()\n","        print(f\"AVERAGE F1 SCORE for all the classes: {np.array(all_f1_score).mean()}\")\n","        print()\n","        y_axis_labels = [\"predicted normal\", \"predicted anomaly\"]\n","        x_axis_labels = [\"true normal\", \"true anomaly\"]\n","        sns.heatmap(tot_conf_matrix/np.sum(tot_conf_matrix), xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot=True, fmt='.2%', cmap='Greens')\n","        # metrics for comparison reason\n","        tna = np.array(all_inner_acc_norm).mean()\n","        taa = np.array(all_inner_acc_anom).mean()\n","        print(\"avg_norm_acc:\", tna)\n","        print(\"avg_anom_acc:\", taa)\n","        print(\"avg_tot_acc:\", (tna+taa)/2)\n","\n","# alternative method to validate our model\n","def performance_evaluation2(model, dataset):\n","    c2id = dataset.c2id\n","    id2c = dataset.id2c\n","    anom_all = Counter()\n","    norm_all = Counter()\n","    anom_class = Counter()\n","    norm_class = Counter()\n","    precision = Precision(task = 'binary', num_classes = 2)\n","    recall = Recall(task = 'binary', num_classes = 2)\n","    f1score = F1Score(task = 'binary', num_classes = 2)\n","    for bat in tqdm(dataset.val_dataloader()):\n","        pred = model.anomaly_prediction(bat[\"img\"])\n","        precision.update(pred, bat[\"label\"])\n","        recall.update(pred, bat[\"label\"])\n","        f1score.update(pred, bat[\"label\"])\n","        fila = bat[\"label\"]>0\n","        filn = bat[\"label\"]==0\n","        anom_all.update([id2c[i] for i in bat[\"class_obj\"][fila].tolist()])\n","        norm_all.update([id2c[i] for i in bat[\"class_obj\"][filn].tolist()])\n","        res = bat[\"label\"]-pred\n","        # if res > 0 anom predicted as normal (wrong anom prediction)\n","        anom_class.update([id2c[i] for i in bat[\"class_obj\"][res>0].tolist()])\n","        # if res < 0 normal predicted as anom\n","        norm_class.update([id2c[i] for i in bat[\"class_obj\"][res<0].tolist()])\n","    for k in anom_all.keys():\n","        alla_k = anom_all[k]\n","        alln_k = norm_all[k]\n","        all = alla_k + alln_k\n","        bada_k = anom_class[k]\n","        badn_k = norm_class[k]\n","        print(f\"there are {all} {k}, anom predicted correctly {(alla_k-bada_k)/alla_k:.3f}, norm predicted correctly {(alln_k-badn_k)/alln_k:.3f}\")\n","    print(f\"final P {precision.compute()}, R {recall.compute()}, F {f1score.compute()}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> Just to have a visual feedback and test our code, we plot some samples from the **train** set (only *normal* samples) and **test** set (*normal* and *anomalous*)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hparams = asdict(Hparams())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MVTec_Data = MVTec_DataModule(hparams)\n","# to setup it takes ~3 minutes\n","MVTec_Data.setup()\n","print(len(MVTec_Data.data_train)) # -->  3629 images\n","print(len(MVTec_Data.data_test)) # -->  1258+467=1725 images\n","print(\"TOTAL: \"+str(len(MVTec_Data.data_train)+len(MVTec_Data.data_test))+\" industrial images\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# depending on python version you can use --> data = iter(dataloader).next() or\n","#                                             data = next(iter(dataloader))\n","batch = next(iter(MVTec_Data.train_dataloader()))\n","plot_objects(MVTec_DataModule.denormalize(batch[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from training dataset\")\n","batch2 = next(iter(MVTec_Data.val_dataloader()))\n","plot_objects(MVTec_DataModule.denormalize(batch2[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from validation dataset\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> ⚡ During our implementation we also tried an additional data extraction strategy in order to make ***data.setup()*** more efficient. <br> At the beginning we thought the slowness of the operation was induced by the many folder accesses and as a result the dataset folder structure is been modified. <br> Unfortunately *NO IMPROVEMENTS* were achieved. In fact the lack of efficiency came from the *image transformations*!"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Autoencoders - **AE**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline - *CNN AE*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# settings for the logger working in a team\n","mixer = False # to identify if it is a mixer or not, during the performance evaluation\n","team_name = \"eai_project\"\n","project_name = \"EAI_Anomaly_Detection\"\n","version_name = \"baseline\"\n","run = wandb.init(entity=team_name, project=project_name, name = version_name, mode = \"online\")\n","\n","ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","model = AE(ae_hparams)\n","trainer = train_model(data, model, experiment_name = version_name, \\\n","    patience=7, metric_to_monitor=\"f1_score\", mode=\"max\", epochs = 100)\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### CNN Advanced AE - **CO**ntractive + **DE**noising"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# settings for the logger working in a team\n","mixer = False\n","team_name = \"eai_project\"\n","project_name = \"EAI_Anomaly_Detection\"\n","# to edit \n","version_name = \"CODE_AE\"\n","run = wandb.init(entity=team_name, project=project_name, name = version_name, mode = \"online\")\n","\n","ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","model = CODE_AE(ae_hparams)\n","trainer = train_model(data,model, experiment_name = version_name, \\\n","    patience=5, metric_to_monitor=\"f1_score\", mode=\"max\", epochs = 100)\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Mixer AE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# settings for the logger working in a team\n","mixer = True\n","team_name = \"eai_project\"\n","project_name = \"EAI_Anomaly_Detection\"\n","# to edit \n","version_name = \"mixer_AE\"\n","run = wandb.init(entity=team_name, project=project_name, name = version_name, mode = \"online\")\n","\n","ae_hparams = asdict(Hparams())\n","print(ae_hparams)\n","data = MVTec_DataModule(ae_hparams)\n","model = Mixer_AE(ae_hparams)\n","trainer = train_model(data,model, experiment_name = version_name, \\\n","    patience=5, metric_to_monitor=\"f1_score\", mode=\"max\", epochs = 100)\n","\n","wandb.finish()\n","\n","trainer.save_checkpoint(f\"models/{version_name}.ckpt\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Test and analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["load_ckpt = True\n","if load_ckpt:\n","    best_ckpt = \"models/mixer_AE_unet-epoch=07-f1_score=0.4214.ckpt\"\n","    model = Mixer_AE.load_from_checkpoint(best_ckpt, strict=False, device = \"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# if we want to test without training we need to setup the data\n","trained = False \n","if not trained:\n","    ae_hparams = asdict(Hparams())\n","    data = MVTec_DataModule(ae_hparams)\n","    data.setup()\n","mixer = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#torch.cuda.empty_cache()\n","model.eval()\n","\n","# TRAIN DATA\n","iterator = iter(data.train_dataloader())\n","batch = iterator.next()\n","plot_objects(MVTec_DataModule.denormalize(batch[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from TRAINING dataset\")\n","\n","if mixer:\n","    batch_recon, _ = model(batch[\"img\"])\n","else:\n","    batch_recon = model(batch[\"img\"].to(model.device))\n","plot_objects(MVTec_DataModule.denormalize(batch_recon[0:40]), images_per_row=8, title=\"Industrial images from TRAINING dataset (RECONSTRUCTED)\")\n","\n","# TEST DATA\n","iterator = iter(data.val_dataloader())\n","batch = iterator.next()\n","plot_objects(MVTec_DataModule.denormalize(batch[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from VALIDATION dataset\")\n","\n","if mixer:\n","    batch_recon, _ = model(batch[\"img\"])\n","else:\n","    batch_recon = model(batch[\"img\"].to(model.device))\n","plot_objects(MVTec_DataModule.denormalize(batch_recon[0:40]), images_per_row=8, title=\"Industrial images from VALIDATION dataset (RECONSTRUCTED)\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# performance evaluation\n","performance_evaluation(model, data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# these are the scores to beat from the paper authors, which is the highest score recorded with CAE \n","scores = [ \n","0.57,0.42,\n","0.57,0.98,\n","0.06,0.82,\n","1.00,0.54,\n","1.00,0.47,\n","0.70,0.89,\n","0.93,0.18,\n","1.00,0.24,\n","0.93,0.84,\n","0.68,0.77,\n","1.00,0.23,\n","0.98,0.39,\n","1.00,0.97,\n","0.97,0.45,\n","0.97,0.63\n","]\n","anomaly_free_acc = [scores[i] for i in range(len(scores)) if i%2 == 0]\n","anomaly_acc = [scores[i] for i in range(len(scores)) if i%2 == 1]\n","print(np.array(anomaly_free_acc).mean())\n","print(np.array(anomaly_acc).mean())\n","print(np.array(scores).mean())"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sYnPaW3xqB76","o_pOiPmDqB78","UM9r2JPLqB79","dWYN7dXdqB7_","-6AfNu4BqB8A","8qebcYffqB8A","jGyjEQYeqB8B","3rN7DegMJpJB","P8ThCPp6Jt5c","7_K0zpGyqB8H","iCFsRmN9qB8I"],"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"dlp","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"},"vscode":{"interpreter":{"hash":"47190f7cb2772d39fc79edc4ccd16e1d5aa2f435aeaf1de6cf1f85c03f1e696f"}}},"nbformat":4,"nbformat_minor":0}
